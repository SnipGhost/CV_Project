#==================================================================================================
# Classic model
#
# X -> [CONV->CONV->POOL]x5 -> DENSE -> DENSE -> Y
#==================================================================================================
import numpy as np
import lasagne
import theano
import theano.tensor as T
from lasagne.nonlinearities import rectify, sigmoid, linear, tanh
from lasagne.layers import InputLayer, DenseLayer, BatchNormLayer, \
                           Upscale2DLayer, NonlinearityLayer, ReshapeLayer
from lasagne.layers import Conv2DLayer, MaxPool2DLayer, dropout
#==================================================================================================
np.random.seed(12)
#==================================================================================================
second_dim = 1
img_size = 160
blocks_count = 5
#==================================================================================================
conv_filter_size = [0 for _ in range(blocks_count)]
conv_num_filters = [0 for _ in range(blocks_count)]
conv_pad =    [0 for _ in range(blocks_count)]
conv_stride = [0 for _ in range(blocks_count)]
#==================================================================================================
conv1_filter_size = 3
conv1_num_filters = 64
conv1_pad = 1
conv1_stride = 1
#==================================================================================================
conv2_filter_size = 3
conv2_num_filters = 128
conv2_pad = 1
conv2_stride = 1
#==================================================================================================
conv3_filter_size = 3
conv3_num_filters = 256
conv3_stride = 1
conv3_pad = 1
#==================================================================================================
conv4_filter_size = 3
conv4_num_filters = 512
conv4_stride = 1
conv4_pad = 1
#==================================================================================================
conv5_filter_size = 3
conv5_num_filters = 512
conv5_stride = 1
conv5_pad = 1
#==================================================================================================
pool1_size = 2
pool2_size = 2
pool3_size = 2
pool4_size = 2
pool5_size = 2
#==================================================================================================
dense_layer1_size = 1024
dense_layer1_drop = 0.5
dense_layer2_size = 512
dense_layer2_drop = 0.5
#==================================================================================================
my_nonlin = rectify
#==================================================================================================
input_image_left     = T.tensor4('input_left')
input_image_positive = T.tensor4('input_positive')
input_image_negative = T.tensor4('input_negative')
#==================================================================================================
l_input = InputLayer(shape=(None, second_dim, img_size, img_size), input_var=input_image_left)
p_input = InputLayer(shape=(None, second_dim, img_size, img_size), input_var=input_image_positive)
n_input = InputLayer(shape=(None, second_dim, img_size, img_size), input_var=input_image_negative)
#==================================================================================================
net = Conv2DLayer(l_input, conv1_num_filters, conv1_filter_size, pad=conv1_pad, stride=conv1_stride,
                  nonlinearity=my_nonlin, W=lasagne.init.GlorotUniform())
net = Conv2DLayer(net, conv1_num_filters, conv1_filter_size, pad=conv1_pad, stride=conv1_stride,
                  nonlinearity=my_nonlin, W=lasagne.init.GlorotUniform())
net = MaxPool2DLayer(net, pool1_size)

net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, pad=conv2_pad, stride=conv2_stride,
                  nonlinearity=my_nonlin)
net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, pad=conv2_pad, stride=conv2_stride,
                  nonlinearity=my_nonlin)
net = MaxPool2DLayer(net, pool2_size)

net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, pad=conv3_pad, stride=conv3_stride,
                  nonlinearity=my_nonlin)
net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, pad=conv3_pad, stride=conv3_stride,
                  nonlinearity=my_nonlin)
net = MaxPool2DLayer(net, pool3_size)

net = Conv2DLayer(net, conv4_num_filters, conv4_filter_size, pad=conv4_pad, stride=conv4_stride,
                  nonlinearity=my_nonlin)
net = Conv2DLayer(net, conv4_num_filters, conv4_filter_size, pad=conv4_pad, stride=conv4_stride,
                  nonlinearity=my_nonlin)
net = MaxPool2DLayer(net, pool4_size)

net = Conv2DLayer(net, conv5_num_filters, conv5_filter_size, pad=conv5_pad, stride=conv5_stride,
                  nonlinearity=my_nonlin)
net = Conv2DLayer(net, conv5_num_filters, conv5_filter_size, pad=conv5_pad, stride=conv5_stride,
                  nonlinearity=my_nonlin)
net = MaxPool2DLayer(net, pool5_size)

net = DenseLayer(dropout(net, p=dense_layer1_drop), num_units=dense_layer1_size, 
                 nonlinearity=my_nonlin)
nn_l_out = DenseLayer(dropout(net, p=dense_layer2_drop), num_units=dense_layer2_size, 
                      nonlinearity=my_nonlin)

l_params = lasagne.layers.get_all_params(nn_l_out)
#==================================================================================================
net = Conv2DLayer(p_input, conv1_num_filters, conv1_filter_size, pad=conv1_pad, stride=conv1_stride, 
                  nonlinearity=my_nonlin, W=l_params[0], b=l_params[1])
net = MaxPool2DLayer(net, pool1_size)
net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, pad=conv2_pad, stride=conv2_stride, 
                  nonlinearity=my_nonlin, W=l_params[2], b=l_params[3])
net = MaxPool2DLayer(net, pool2_size)
net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, pad=conv3_pad, stride=conv3_stride, 
                  nonlinearity=my_nonlin, W=l_params[4], b=l_params[5])
net = MaxPool2DLayer(net, pool3_size)
net = Conv2DLayer(net, conv4_num_filters, conv4_filter_size, pad=conv4_pad, stride=conv4_stride,
                  nonlinearity=my_nonlin, W=l_params[6], b=l_params[7])
net = MaxPool2DLayer(net, pool4_size)
net = Conv2DLayer(net, conv5_num_filters, conv5_filter_size, pad=conv5_pad, stride=conv5_stride,
                  nonlinearity=my_nonlin, W=l_params[8], b=l_params[9])
net = MaxPool2DLayer(net, pool5_size)
net = DenseLayer(dropout(net, p=dense_layer1_drop), num_units=dense_layer1_size, nonlinearity=my_nonlin,
                 W=l_params[10], b=l_params[11])
nn_p_out = DenseLayer(dropout(net, p=dense_layer2_drop), num_units=dense_layer2_size, nonlinearity=my_nonlin,
                 W=l_params[12], b=l_params[13])

net = Conv2DLayer(n_input, conv1_num_filters, conv1_filter_size, pad=conv1_pad, stride=conv1_stride,
                      nonlinearity=my_nonlin,
                      W=l_params[0], b=l_params[1])
net = MaxPool2DLayer(net, pool1_size)
net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, pad=conv2_pad, stride=conv2_stride,
                  nonlinearity=my_nonlin,
                  W=l_params[2], b=l_params[3])
net = MaxPool2DLayer(net, pool2_size)
net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, pad=conv3_pad, stride=conv3_stride,
                  nonlinearity=my_nonlin,
                  W=l_params[4], b=l_params[5])
net = MaxPool2DLayer(net, pool3_size)
net = Conv2DLayer(net, conv4_num_filters, conv4_filter_size, pad=conv4_pad, stride=conv4_stride,
                  nonlinearity=my_nonlin,
                  W=l_params[6], b=l_params[7])
net = MaxPool2DLayer(net, pool4_size)
net = Conv2DLayer(net, conv5_num_filters, conv5_filter_size, pad=conv5_pad, stride=conv5_stride,
                  nonlinearity=my_nonlin,
                  W=l_params[8], b=l_params[9])
net = MaxPool2DLayer(net, pool5_size)
net = DenseLayer(dropout(net, p=0.5), num_units=dense_layer1_size, nonlinearity=my_nonlin,
                 W=l_params[10], b=l_params[11])
nn_n_out = DenseLayer(dropout(net, p=0.5), num_units=dense_layer2_size, nonlinearity=my_nonlin,
                      W=l_params[12], b=l_params[13])

nn_merge = lasagne.layers.concat([nn_l_out, nn_p_out, nn_n_out], axis=1)
nn_out  = lasagne.layers.get_output(nn_merge, deterministic=False)
nn_out_test  = lasagne.layers.get_output(nn_merge, deterministic=True)
nn_out_left = nn_out[:, :dense_layer2_size]
nn_out_positive = nn_out[:, dense_layer2_size:dense_layer1_size]
nn_out_negative = nn_out[:, dense_layer1_size:]

nn_out_left_test = nn_out_test[:, :dense_layer2_size]
nn_out_positive_test = nn_out_test[:, dense_layer2_size:dense_layer1_size]
nn_out_negative_test = nn_out_test[:, dense_layer1_size:]

a = T.scalar()

d1 = T.sum(T.sqr(nn_out_left - nn_out_positive), axis=1)
d2 = T.sum(T.sqr(nn_out_left - nn_out_negative), axis=1)

loss = T.sum(T.maximum(T.sqr(d1) - T.sqr(d2) + a, 0.))

d1_test = T.sum(T.sqr(nn_out_left_test - nn_out_positive_test), axis=1)
d2_test = T.sum(T.sqr(nn_out_left_test - nn_out_negative_test), axis=1)

test_loss = T.sum(T.maximum(T.sqr(d1_test) - T.sqr(d2_test) + a, 0.))

params = lasagne.layers.get_all_params(nn_merge)

updates = lasagne.updates.adamax(loss, params)


train_fn = theano.function([input_image_left, input_image_positive, input_image_negative, a], loss, 
                           updates=updates, allow_input_downcast=True)

val_fn = theano.function([input_image_left, input_image_positive, input_image_negative, a], test_loss, 
                         updates=updates, allow_input_downcast=True)

test_fn = theano.function([input_image_left, input_image_positive, input_image_negative], [d1_test, d2_test], 
                          allow_input_downcast=True)
