{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Собираем-сиамскую-сеть\" data-toc-modified-id=\"Собираем-сиамскую-сеть-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Собираем сиамскую сеть</a></div><div class=\"lev1 toc-item\"><a href=\"#Проверяем-глубокое-представление\" data-toc-modified-id=\"Проверяем-глубокое-представление-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Проверяем глубокое представление</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne.nonlinearities import rectify, sigmoid, linear, tanh\n",
    "from lasagne.layers import InputLayer, DenseLayer, BatchNormLayer, Upscale2DLayer, NonlinearityLayer, ReshapeLayer\n",
    "from lasagne.layers import Conv2DLayer, MaxPool2DLayer, dropout\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import gzip, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "files = np.load('data_set.npz')\n",
    "X_train, y_train, X_val, y_val = files['X_train'], files['y_train'], files['X_test'], files['y_test']\n",
    "# Load training and test splits as numpy arrays\n",
    "# train, val, test = pickle.load(gzip.open('mnist.pkl.gz'))\n",
    "\n",
    "# X_train, y_train = train\n",
    "# X_val, y_val = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((11450, 1, 150, 150), (1783, 1, 150, 150))\n"
     ]
    }
   ],
   "source": [
    "second_dim = 1\n",
    "img_size = 150\n",
    "print(X_train.shape, X_val.shape)\n",
    "\n",
    "# second_dim = 1\n",
    "# img_size = 28\n",
    "# X_train = X_train.reshape([-1,1,28,28])\n",
    "# X_val = X_val.reshape([-1,1,28,28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Собираем сиамскую сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_image_left  = T.tensor4('input_left')\n",
    "input_image_positive = T.tensor4('input_positive')\n",
    "input_image_negative = T.tensor4('input_negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l_input = InputLayer(shape=(None, second_dim, img_size, img_size), input_var=input_image_left)\n",
    "p_input = InputLayer(shape=(None, second_dim, img_size, img_size), input_var=input_image_positive)\n",
    "n_input = InputLayer(shape=(None, second_dim, img_size, img_size), input_var=input_image_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv1_filter_size = (5, 5)\n",
    "conv1_num_filters = 16\n",
    "conv2_filter_size = (3, 3)\n",
    "conv2_num_filters = 32\n",
    "conv2_stride = (1, 1)\n",
    "conv3_filter_size = (3, 3)\n",
    "conv3_num_filters = 32\n",
    "conv3_stride = (1, 1)\n",
    "pool1_size = (2, 2)\n",
    "pool2_size = (2, 2)\n",
    "pool3_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lasagne.layers.dense.DenseLayer at 0x7f77885fadd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nonlin = rectify\n",
    "net = Conv2DLayer(l_input, conv1_num_filters, conv1_filter_size, nonlinearity=my_nonlin, W=lasagne.init.GlorotUniform())\n",
    "net = MaxPool2DLayer(net, pool1_size)\n",
    "net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, stride=conv2_stride, nonlinearity=my_nonlin)\n",
    "net = MaxPool2DLayer(net, pool2_size)\n",
    "net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, stride=conv3_stride, nonlinearity=my_nonlin)\n",
    "net = MaxPool2DLayer(net, pool3_size)\n",
    "net = DenseLayer(dropout(net, p=.5), num_units=256, nonlinearity=my_nonlin)\n",
    "nn_l_out = DenseLayer(dropout(net, p=.5), num_units=128, nonlinearity=my_nonlin)\n",
    "nn_l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[W, b, W, b, W, b, W, b, W, b]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_params = lasagne.layers.get_all_params(nn_l_out)\n",
    "l_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = Conv2DLayer(p_input, conv1_num_filters, conv1_filter_size, nonlinearity=my_nonlin, W=l_params[0], b=l_params[1])\n",
    "net = MaxPool2DLayer(net, pool1_size)\n",
    "net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, stride = conv2_stride, nonlinearity=my_nonlin, W=l_params[2], b=l_params[3])\n",
    "net = MaxPool2DLayer(net, pool2_size)\n",
    "net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, stride = conv3_stride, nonlinearity=my_nonlin, W=l_params[4], b=l_params[5])\n",
    "net = MaxPool2DLayer(net, pool3_size)\n",
    "net = DenseLayer(dropout(net, p=0.5), num_units=256, nonlinearity=my_nonlin, W=l_params[6], b=l_params[7])\n",
    "nn_p_out = DenseLayer(dropout(net, p=0.5), num_units=128, nonlinearity=my_nonlin, W=l_params[8], b=l_params[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "net = Conv2DLayer(n_input, conv1_num_filters, conv1_filter_size, nonlinearity=my_nonlin, W=l_params[0], b=l_params[1])\n",
    "net = MaxPool2DLayer(net, pool1_size)\n",
    "net = Conv2DLayer(net, conv2_num_filters, conv2_filter_size, stride = conv2_stride, nonlinearity=my_nonlin, W=l_params[2], b=l_params[3])\n",
    "net = MaxPool2DLayer(net, pool2_size)\n",
    "net = Conv2DLayer(net, conv3_num_filters, conv3_filter_size, stride = conv3_stride, nonlinearity=my_nonlin, W=l_params[4], b=l_params[5])\n",
    "net = MaxPool2DLayer(net, pool3_size)\n",
    "net = DenseLayer(dropout(net, p=0.5), num_units=256, nonlinearity=my_nonlin, W=l_params[6], b=l_params[7])\n",
    "nn_n_out = DenseLayer(dropout(net, p=0.5), num_units=128, nonlinearity=my_nonlin, W=l_params[8], b=l_params[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn_merge = lasagne.layers.concat([nn_l_out, nn_p_out, nn_n_out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn_out  = lasagne.layers.get_output(nn_merge, deterministic=False)\n",
    "nn_out_test  = lasagne.layers.get_output(nn_merge, deterministic=True)\n",
    "nn_out_left = nn_out[:, :128]\n",
    "nn_out_positive = nn_out[:, 128:256]\n",
    "nn_out_negative = nn_out[:, 256:]\n",
    "\n",
    "nn_out_left_test = nn_out_test[:, :128]\n",
    "nn_out_positive_test = nn_out_test[:, 128:256]\n",
    "nn_out_negative_test = nn_out_test[:, 256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = T.scalar()\n",
    "\n",
    "d1 = T.sum(T.sqr(nn_out_left - nn_out_positive), axis=1)\n",
    "d2 = T.sum(T.sqr(nn_out_left - nn_out_negative), axis=1)\n",
    "\n",
    "loss = T.sum(T.maximum(T.sqr(d1) - T.sqr(d2) + a, 0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d1_test = T.sum(T.sqr(nn_out_left_test - nn_out_positive_test), axis=1)\n",
    "d2_test = T.sum(T.sqr(nn_out_left_test - nn_out_negative_test), axis=1)\n",
    "\n",
    "test_loss = T.sum(T.maximum(T.sqr(d1_test) - T.sqr(d2_test) + a, 0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params(nn_merge)\n",
    "# updates = lasagne.updates.rmsprop(loss, params)\n",
    "updates = lasagne.updates.adamax(loss, params)\n",
    "# updates = lasagne.updates.nesterov_momentum(loss, params, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_image_left, input_image_positive, input_image_negative, a], loss, \n",
    "                           updates=updates, allow_input_downcast=True)\n",
    "val_fn = theano.function([input_image_left, input_image_positive, input_image_negative, a], test_loss, \n",
    "                         updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchs_per_epoch=100, batchsize=20, train=True, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "\n",
    "    left_indices = np.arange(len(inputs))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(left_indices)\n",
    "        \n",
    "    for _ in range(batchs_per_epoch):\n",
    "        full_lft_indxs = []\n",
    "        full_pos_indxs = []\n",
    "        full_neg_indxs = []\n",
    "        \n",
    "        for _ in range(batchsize):\n",
    "            start_idx = np.random.randint(low=0, high=len(left_indices))\n",
    "            full_lft_indxs.append(start_idx)\n",
    "            \n",
    "            pos_idxs = np.where(targets == targets[start_idx])[0]\n",
    "            b_idxs = np.random.randint(low=0, high=len(pos_idxs), size=1)\n",
    "            full_pos_indxs.append(pos_idxs[b_idxs[0]])\n",
    "            \n",
    "            neg_idxs = np.where(targets != targets[start_idx])[0]\n",
    "            b_idxs = np.random.randint(low=0, high=len(neg_idxs), size=1)\n",
    "            full_neg_indxs.append(neg_idxs[b_idxs[0]])\n",
    "\n",
    "        full_lft_indxs = np.array(full_lft_indxs)\n",
    "        full_pos_indxs = np.array(full_pos_indxs)\n",
    "        full_neg_indxs = np.array(full_neg_indxs)\n",
    "        \n",
    "        yield inputs[full_lft_indxs], inputs[full_pos_indxs], inputs[full_neg_indxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "epoch = 0\n",
    "batch_size = 20\n",
    "batchs_per_epoch = 5\n",
    "\n",
    "margin = 1.242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221719344.0\n",
      "Epoch 1 of 200 took 37.240s\n",
      "  training loss:\t\t14749571593.600000\n",
      "  validation loss:\t\t160986.432812\n",
      "11047425.0\n",
      "Epoch 2 of 200 took 38.466s\n",
      "  training loss:\t\t13530965.600000\n",
      "  validation loss:\t\t48793.033984\n",
      "5431138.0\n",
      "Epoch 3 of 200 took 33.555s\n",
      "  training loss:\t\t3839434.550000\n",
      "  validation loss:\t\t20025.615723\n",
      "1851132.25\n",
      "Epoch 4 of 200 took 34.078s\n",
      "  training loss:\t\t2201709.825000\n",
      "  validation loss:\t\t16307.556641\n",
      "2359308.0\n",
      "Epoch 5 of 200 took 33.842s\n",
      "  training loss:\t\t1935375.100000\n",
      "  validation loss:\t\t10612.746362\n",
      "1114682.625\n",
      "Epoch 6 of 200 took 38.677s\n",
      "  training loss:\t\t1734635.525000\n",
      "  validation loss:\t\t16111.405908\n",
      "897551.75\n",
      "Epoch 7 of 200 took 34.895s\n",
      "  training loss:\t\t1350526.537500\n",
      "  validation loss:\t\t18499.846240\n",
      "723828.5625\n",
      "Epoch 8 of 200 took 39.200s\n",
      "  training loss:\t\t1729467.212500\n",
      "  validation loss:\t\t13441.746094\n",
      "689157.625\n",
      "Epoch 9 of 200 took 30.484s\n",
      "  training loss:\t\t643087.968750\n",
      "  validation loss:\t\t12014.570312\n",
      "866777.625\n",
      "Epoch 10 of 200 took 36.294s\n",
      "  training loss:\t\t1248941.150000\n",
      "  validation loss:\t\t11178.754980\n",
      "183737.78125\n",
      "Epoch 11 of 200 took 41.487s\n",
      "  training loss:\t\t593997.950000\n",
      "  validation loss:\t\t7424.906787\n",
      "1408472.0\n",
      "Epoch 12 of 200 took 48.403s\n",
      "  training loss:\t\t903122.231250\n",
      "  validation loss:\t\t8313.794043\n",
      "786163.625\n",
      "Epoch 13 of 200 took 36.701s\n",
      "  training loss:\t\t925024.325000\n",
      "  validation loss:\t\t6582.688574\n",
      "237131.5625\n",
      "Epoch 14 of 200 took 50.802s\n",
      "  training loss:\t\t337645.487500\n",
      "  validation loss:\t\t10364.096582\n",
      "1247084.875\n",
      "Epoch 15 of 200 took 34.271s\n",
      "  training loss:\t\t1036028.662500\n",
      "  validation loss:\t\t8905.158984\n",
      "773609.1875\n",
      "Epoch 16 of 200 took 35.587s\n",
      "  training loss:\t\t695799.612500\n",
      "  validation loss:\t\t6974.308350\n",
      "568742.25\n",
      "Epoch 17 of 200 took 40.667s\n",
      "  training loss:\t\t610988.146875\n",
      "  validation loss:\t\t9180.229004\n",
      "380157.40625\n",
      "Epoch 18 of 200 took 27.641s\n",
      "  training loss:\t\t510530.206250\n",
      "  validation loss:\t\t11668.182812\n",
      "184057.71875\n",
      "Epoch 19 of 200 took 33.681s\n",
      "  training loss:\t\t260047.560938\n",
      "  validation loss:\t\t4565.704272\n",
      "692030.125\n",
      "Epoch 20 of 200 took 50.313s\n",
      "  training loss:\t\t541932.903125\n",
      "  validation loss:\t\t6887.113135\n",
      "1200160.875\n",
      "Epoch 21 of 200 took 33.616s\n",
      "  training loss:\t\t541103.743750\n",
      "  validation loss:\t\t3068.262183\n",
      "477352.21875\n",
      "Epoch 22 of 200 took 33.943s\n",
      "  training loss:\t\t440041.546875\n",
      "  validation loss:\t\t4537.226099\n",
      "160927.71875\n",
      "Epoch 23 of 200 took 43.506s\n",
      "  training loss:\t\t281242.120312\n",
      "  validation loss:\t\t6158.813159\n",
      "235206.21875\n",
      "Epoch 24 of 200 took 43.604s\n",
      "  training loss:\t\t269003.506250\n",
      "  validation loss:\t\t3876.690576\n",
      "412493.78125\n",
      "Epoch 25 of 200 took 40.207s\n",
      "  training loss:\t\t286341.368750\n",
      "  validation loss:\t\t6396.202002\n",
      "252004.1875\n",
      "Epoch 26 of 200 took 34.249s\n",
      "  training loss:\t\t268390.132812\n",
      "  validation loss:\t\t6749.775195\n",
      "53190.9101562\n",
      "Epoch 27 of 200 took 31.307s\n",
      "  training loss:\t\t193445.157031\n",
      "  validation loss:\t\t5891.170410\n",
      "309569.65625\n",
      "Epoch 28 of 200 took 30.808s\n",
      "  training loss:\t\t243297.064062\n",
      "  validation loss:\t\t6326.724365\n",
      "367567.65625\n",
      "Epoch 29 of 200 took 31.233s\n",
      "  training loss:\t\t385154.634375\n",
      "  validation loss:\t\t2752.885645\n",
      "325755.03125\n",
      "Epoch 30 of 200 took 44.698s\n",
      "  training loss:\t\t306469.853125\n",
      "  validation loss:\t\t7318.992285\n",
      "196592.046875\n",
      "Epoch 31 of 200 took 31.432s\n",
      "  training loss:\t\t232731.393750\n",
      "  validation loss:\t\t8898.768994\n",
      "194739.875\n",
      "Epoch 32 of 200 took 30.631s\n",
      "  training loss:\t\t343170.717187\n",
      "  validation loss:\t\t3775.992285\n",
      "121495.070312\n",
      "Epoch 33 of 200 took 42.559s\n",
      "  training loss:\t\t324275.939063\n",
      "  validation loss:\t\t1551.143941\n",
      "691638.625\n",
      "Epoch 34 of 200 took 35.499s\n",
      "  training loss:\t\t325510.793750\n",
      "  validation loss:\t\t3791.224048\n",
      "314831.96875\n",
      "Epoch 35 of 200 took 35.661s\n",
      "  training loss:\t\t418235.437500\n",
      "  validation loss:\t\t2257.344873\n",
      "163349.75\n",
      "Epoch 36 of 200 took 41.215s\n",
      "  training loss:\t\t155048.909375\n",
      "  validation loss:\t\t3237.103906\n",
      "143626.484375\n",
      "Epoch 37 of 200 took 41.768s\n",
      "  training loss:\t\t204415.220312\n",
      "  validation loss:\t\t3403.552246\n",
      "347156.375\n",
      "Epoch 38 of 200 took 35.577s\n",
      "  training loss:\t\t180099.212500\n",
      "  validation loss:\t\t7036.694287\n",
      "519744.28125\n",
      "Epoch 39 of 200 took 29.017s\n",
      "  training loss:\t\t320485.057812\n",
      "  validation loss:\t\t2181.724213\n",
      "229007.1875\n",
      "Epoch 40 of 200 took 29.833s\n",
      "  training loss:\t\t248816.140625\n",
      "  validation loss:\t\t3525.203882\n",
      "111913.476562\n",
      "Epoch 41 of 200 took 31.046s\n",
      "  training loss:\t\t196837.182812\n",
      "  validation loss:\t\t4439.125635\n",
      "280243.1875\n",
      "Epoch 42 of 200 took 27.689s\n",
      "  training loss:\t\t327561.146875\n",
      "  validation loss:\t\t3865.273413\n",
      "321737.84375\n",
      "Epoch 43 of 200 took 26.201s\n",
      "  training loss:\t\t191335.309375\n",
      "  validation loss:\t\t2851.264526\n",
      "138062.5625\n",
      "Epoch 44 of 200 took 30.152s\n",
      "  training loss:\t\t169015.373438\n",
      "  validation loss:\t\t3234.021997\n",
      "117471.109375\n",
      "Epoch 45 of 200 took 38.600s\n",
      "  training loss:\t\t161017.257812\n",
      "  validation loss:\t\t3134.518481\n",
      "329867.25\n",
      "Epoch 46 of 200 took 27.517s\n",
      "  training loss:\t\t183987.928125\n",
      "  validation loss:\t\t3139.750903\n",
      "111098.015625\n",
      "Epoch 47 of 200 took 27.085s\n",
      "  training loss:\t\t159455.146875\n",
      "  validation loss:\t\t2228.301654\n",
      "175464.28125\n",
      "Epoch 48 of 200 took 28.825s\n",
      "  training loss:\t\t178974.356250\n",
      "  validation loss:\t\t3024.812183\n",
      "80002.6796875\n",
      "Epoch 49 of 200 took 33.425s\n",
      "  training loss:\t\t92517.992188\n",
      "  validation loss:\t\t4653.326575\n",
      "212267.3125\n",
      "Epoch 50 of 200 took 27.396s\n",
      "  training loss:\t\t233124.702734\n",
      "  validation loss:\t\t2457.533539\n",
      "216017.21875\n",
      "Epoch 51 of 200 took 27.264s\n",
      "  training loss:\t\t201765.912500\n",
      "  validation loss:\t\t1644.805469\n",
      "173558.890625\n",
      "Epoch 52 of 200 took 26.865s\n",
      "  training loss:\t\t153373.685938\n",
      "  validation loss:\t\t3148.936230\n",
      "85882.890625\n",
      "Epoch 53 of 200 took 26.974s\n",
      "  training loss:\t\t198999.262500\n",
      "  validation loss:\t\t3024.738940\n",
      "261284.984375\n",
      "Epoch 54 of 200 took 26.600s\n",
      "  training loss:\t\t286669.571875\n",
      "  validation loss:\t\t2988.361279\n",
      "89413.078125\n",
      "Epoch 55 of 200 took 26.622s\n",
      "  training loss:\t\t128007.682813\n",
      "  validation loss:\t\t4297.214014\n",
      "75164.6796875\n",
      "Epoch 56 of 200 took 27.851s\n",
      "  training loss:\t\t146259.692188\n",
      "  validation loss:\t\t2780.240234\n",
      "45368.7617188\n",
      "Epoch 57 of 200 took 26.270s\n",
      "  training loss:\t\t164204.114844\n",
      "  validation loss:\t\t1659.760791\n",
      "86456.6796875\n",
      "Epoch 58 of 200 took 27.102s\n",
      "  training loss:\t\t158187.462500\n",
      "  validation loss:\t\t4192.087744\n",
      "186229.21875\n",
      "Epoch 59 of 200 took 28.645s\n",
      "  training loss:\t\t122365.623438\n",
      "  validation loss:\t\t3339.858148\n",
      "51050.2578125\n",
      "Epoch 60 of 200 took 27.165s\n",
      "  training loss:\t\t128314.359375\n",
      "  validation loss:\t\t3471.681360\n",
      "69881.5703125\n",
      "Epoch 61 of 200 took 32.057s\n",
      "  training loss:\t\t113546.367188\n",
      "  validation loss:\t\t3072.553223\n",
      "94377.2890625\n",
      "Epoch 62 of 200 took 27.758s\n",
      "  training loss:\t\t137669.565625\n",
      "  validation loss:\t\t2809.518225\n",
      "185404.453125\n",
      "Epoch 63 of 200 took 31.019s\n",
      "  training loss:\t\t131975.160938\n",
      "  validation loss:\t\t2147.308081\n",
      "129551.257812\n",
      "Epoch 64 of 200 took 29.423s\n",
      "  training loss:\t\t152040.673437\n",
      "  validation loss:\t\t2511.994800\n",
      "93447.828125\n",
      "Epoch 65 of 200 took 37.768s\n",
      "  training loss:\t\t112251.710938\n",
      "  validation loss:\t\t1583.673877\n",
      "96979.078125\n",
      "Epoch 66 of 200 took 27.016s\n",
      "  training loss:\t\t91489.295313\n",
      "  validation loss:\t\t2580.100928\n",
      "93397.84375\n",
      "Epoch 67 of 200 took 27.065s\n",
      "  training loss:\t\t128470.392969\n",
      "  validation loss:\t\t3296.679120\n",
      "57053.9609375\n",
      "Epoch 68 of 200 took 35.390s\n",
      "  training loss:\t\t117799.314062\n",
      "  validation loss:\t\t2333.080042\n",
      "74654.1328125\n",
      "Epoch 69 of 200 took 35.508s\n",
      "  training loss:\t\t66688.637500\n",
      "  validation loss:\t\t1818.492358\n",
      "35034.640625\n",
      "Epoch 70 of 200 took 39.206s\n",
      "  training loss:\t\t77535.614062\n",
      "  validation loss:\t\t1393.234021\n",
      "93315.21875\n",
      "Epoch 71 of 200 took 47.049s\n",
      "  training loss:\t\t78672.168750\n",
      "  validation loss:\t\t1645.084998\n",
      "132875.421875\n",
      "Epoch 72 of 200 took 37.598s\n",
      "  training loss:\t\t119601.552344\n",
      "  validation loss:\t\t2629.909424\n",
      "87205.265625\n",
      "Epoch 73 of 200 took 46.019s\n",
      "  training loss:\t\t54758.766602\n",
      "  validation loss:\t\t2268.447116\n",
      "74508.4609375\n",
      "Epoch 74 of 200 took 42.057s\n",
      "  training loss:\t\t90176.362500\n",
      "  validation loss:\t\t2969.516479\n",
      "78095.6875\n",
      "Epoch 75 of 200 took 37.577s\n",
      "  training loss:\t\t117813.020312\n",
      "  validation loss:\t\t3296.589844\n",
      "89887.8984375\n",
      "Epoch 76 of 200 took 36.192s\n",
      "  training loss:\t\t139685.310938\n",
      "  validation loss:\t\t1867.471521\n",
      "115362.703125\n",
      "Epoch 77 of 200 took 37.945s\n",
      "  training loss:\t\t123891.131250\n",
      "  validation loss:\t\t1709.173474\n",
      "53196.1640625\n",
      "Epoch 78 of 200 took 38.447s\n",
      "  training loss:\t\t59701.539062\n",
      "  validation loss:\t\t1400.472729\n",
      "129041.976562\n",
      "Epoch 79 of 200 took 45.426s\n",
      "  training loss:\t\t99561.162500\n",
      "  validation loss:\t\t1868.048438\n",
      "64201.125\n",
      "Epoch 80 of 200 took 41.452s\n",
      "  training loss:\t\t82115.528418\n",
      "  validation loss:\t\t2249.485767\n",
      "70187.1640625\n",
      "Epoch 81 of 200 took 30.499s\n",
      "  training loss:\t\t97665.889453\n",
      "  validation loss:\t\t1920.483765\n",
      "54256.78125\n",
      "Epoch 84 of 200 took 31.265s\n",
      "  training loss:\t\t97173.806250\n",
      "  validation loss:\t\t1500.347653\n",
      "123684.273438\n",
      "Epoch 85 of 200 took 29.729s\n",
      "  training loss:\t\t104877.243750\n",
      "  validation loss:\t\t1974.189954\n",
      "44940.3046875\n",
      "Epoch 86 of 200 took 31.606s\n",
      "  training loss:\t\t69522.010938\n",
      "  validation loss:\t\t1995.824805\n",
      "12003.2041016\n",
      "Epoch 87 of 200 took 26.451s\n",
      "  training loss:\t\t71809.431445\n",
      "  validation loss:\t\t1487.482327\n",
      "126351.1875\n",
      "Epoch 88 of 200 took 26.617s\n",
      "  training loss:\t\t82014.966406\n",
      "  validation loss:\t\t1563.965747\n",
      "66405.7265625\n",
      "Epoch 89 of 200 took 31.799s\n",
      "  training loss:\t\t121373.851562\n",
      "  validation loss:\t\t2226.484277\n",
      "70770.4140625\n",
      "Epoch 90 of 200 took 40.959s\n",
      "  training loss:\t\t135864.285938\n",
      "  validation loss:\t\t1015.640088\n",
      "71513.3359375\n",
      "Epoch 91 of 200 took 31.592s\n",
      "  training loss:\t\t102262.341406\n",
      "  validation loss:\t\t2399.404443\n",
      "11544.8037109\n",
      "Epoch 92 of 200 took 43.286s\n",
      "  training loss:\t\t79884.320898\n",
      "  validation loss:\t\t2452.180301\n",
      "38441.7382812\n",
      "Epoch 93 of 200 took 34.297s\n",
      "  training loss:\t\t95815.538281\n",
      "  validation loss:\t\t1313.132071\n",
      "129318.164062\n",
      "Epoch 94 of 200 took 26.027s\n",
      "  training loss:\t\t74483.155859\n",
      "  validation loss:\t\t1106.809375\n",
      "23963.5332031\n",
      "Epoch 95 of 200 took 26.556s\n",
      "  training loss:\t\t42847.437109\n",
      "  validation loss:\t\t1474.719620\n",
      "41109.1875\n",
      "Epoch 96 of 200 took 26.398s\n",
      "  training loss:\t\t84014.056250\n",
      "  validation loss:\t\t1573.465295\n",
      "99132.0\n",
      "Epoch 97 of 200 took 26.210s\n",
      "  training loss:\t\t75283.431250\n",
      "  validation loss:\t\t1536.423138\n",
      "71135.0078125\n",
      "Epoch 98 of 200 took 26.597s\n",
      "  training loss:\t\t70202.233203\n",
      "  validation loss:\t\t1762.119379\n",
      "93486.5\n",
      "Epoch 99 of 200 took 27.077s\n",
      "  training loss:\t\t62280.902344\n",
      "  validation loss:\t\t832.623792\n",
      "127387.4375\n",
      "Epoch 100 of 200 took 26.016s\n",
      "  training loss:\t\t57893.649609\n",
      "  validation loss:\t\t1038.053876\n",
      "56811.6328125\n",
      "Epoch 101 of 200 took 27.366s\n",
      "  training loss:\t\t75135.831641\n",
      "  validation loss:\t\t1603.139539\n",
      "22168.2890625\n",
      "Epoch 102 of 200 took 26.667s\n",
      "  training loss:\t\t51443.123437\n",
      "  validation loss:\t\t1042.090845\n",
      "82155.1484375\n",
      "Epoch 103 of 200 took 26.201s\n",
      "  training loss:\t\t51035.057617\n",
      "  validation loss:\t\t2649.758044\n",
      "52633.9414062\n",
      "Epoch 104 of 200 took 26.704s\n",
      "  training loss:\t\t58810.453906\n",
      "  validation loss:\t\t1469.067432\n",
      "52688.4375\n",
      "Epoch 105 of 200 took 27.212s\n",
      "  training loss:\t\t50474.690625\n",
      "  validation loss:\t\t638.409454\n",
      "192560.3125\n",
      "Epoch 106 of 200 took 27.657s\n",
      "  training loss:\t\t56595.847852\n",
      "  validation loss:\t\t1192.714197\n",
      "17578.9355469\n",
      "Epoch 107 of 200 took 27.650s\n",
      "  training loss:\t\t73738.481641\n",
      "  validation loss:\t\t1956.559277\n",
      "46363.7304688\n",
      "Epoch 108 of 200 took 24.600s\n",
      "  training loss:\t\t38679.124805\n",
      "  validation loss:\t\t1171.743073\n",
      "88632.671875\n",
      "Epoch 109 of 200 took 27.560s\n",
      "  training loss:\t\t81161.772656\n",
      "  validation loss:\t\t682.761578\n",
      "42276.6445312\n",
      "Epoch 110 of 200 took 27.237s\n",
      "  training loss:\t\t57926.785156\n",
      "  validation loss:\t\t1060.498523\n",
      "76848.5703125\n",
      "Epoch 111 of 200 took 28.785s\n",
      "  training loss:\t\t58910.761523\n",
      "  validation loss:\t\t904.960254\n",
      "104468.234375\n",
      "Epoch 112 of 200 took 27.985s\n",
      "  training loss:\t\t91810.262109\n",
      "  validation loss:\t\t1902.351880\n",
      "193817.046875\n",
      "Epoch 113 of 200 took 31.091s\n",
      "  training loss:\t\t85646.946484\n",
      "  validation loss:\t\t1317.825415\n",
      "30566.1171875\n",
      "Epoch 114 of 200 took 38.410s\n",
      "  training loss:\t\t40976.124219\n",
      "  validation loss:\t\t1823.123511\n",
      "62080.9179688\n",
      "Epoch 115 of 200 took 42.823s\n",
      "  training loss:\t\t78459.969531\n",
      "  validation loss:\t\t1081.971973\n",
      "61708.4570312\n",
      "Epoch 116 of 200 took 32.344s\n",
      "  training loss:\t\t58083.710156\n",
      "  validation loss:\t\t1376.894165\n",
      "76249.71875\n",
      "Epoch 117 of 200 took 27.769s\n",
      "  training loss:\t\t61953.446875\n",
      "  validation loss:\t\t909.029590\n",
      "37519.546875\n",
      "Epoch 118 of 200 took 32.292s\n",
      "  training loss:\t\t59809.146875\n",
      "  validation loss:\t\t1992.938733\n",
      "88850.8828125\n",
      "Epoch 119 of 200 took 33.329s\n",
      "  training loss:\t\t70965.455078\n",
      "  validation loss:\t\t994.012598\n",
      "132477.671875\n",
      "Epoch 120 of 200 took 28.968s\n",
      "  training loss:\t\t41130.100781\n",
      "  validation loss:\t\t1024.878070\n",
      "49665.6992188\n",
      "Epoch 121 of 200 took 32.879s\n",
      "  training loss:\t\t46938.478906\n",
      "  validation loss:\t\t1090.622766\n",
      "74427.40625\n",
      "Epoch 122 of 200 took 29.506s\n",
      "  training loss:\t\t50254.997461\n",
      "  validation loss:\t\t1138.477075\n",
      "59879.8789062\n",
      "Epoch 123 of 200 took 33.248s\n",
      "  training loss:\t\t74058.212891\n",
      "  validation loss:\t\t1588.927588\n",
      "51224.9492188\n",
      "Epoch 124 of 200 took 40.905s\n",
      "  training loss:\t\t50510.900781\n",
      "  validation loss:\t\t1542.125293\n",
      "18925.703125\n",
      "Epoch 125 of 200 took 41.836s\n",
      "  training loss:\t\t27824.359766\n",
      "  validation loss:\t\t759.754169\n",
      "21801.3457031\n",
      "Epoch 126 of 200 took 30.430s\n",
      "  training loss:\t\t39291.649609\n",
      "  validation loss:\t\t2165.999988\n",
      "92537.34375\n",
      "Epoch 127 of 200 took 30.848s\n",
      "  training loss:\t\t82404.437500\n",
      "  validation loss:\t\t803.893689\n",
      "35497.1328125\n",
      "Epoch 128 of 200 took 34.467s\n",
      "  training loss:\t\t34505.437500\n",
      "  validation loss:\t\t1781.830548\n",
      "88001.5234375\n",
      "Epoch 129 of 200 took 33.322s\n",
      "  training loss:\t\t49687.491406\n",
      "  validation loss:\t\t881.574109\n",
      "78620.375\n",
      "Epoch 130 of 200 took 29.285s\n",
      "  training loss:\t\t58415.146484\n",
      "  validation loss:\t\t1095.068311\n",
      "88025.3046875\n",
      "Epoch 131 of 200 took 29.441s\n",
      "  training loss:\t\t50243.858594\n",
      "  validation loss:\t\t625.220349\n",
      "137308.75\n",
      "Epoch 132 of 200 took 29.822s\n",
      "  training loss:\t\t67032.130078\n",
      "  validation loss:\t\t1024.959097\n",
      "21562.9765625\n",
      "Epoch 133 of 200 took 32.825s\n",
      "  training loss:\t\t41639.883594\n",
      "  validation loss:\t\t561.051801\n",
      "49803.9257812\n",
      "Epoch 134 of 200 took 30.477s\n",
      "  training loss:\t\t47993.569922\n",
      "  validation loss:\t\t745.059171\n",
      "38011.203125\n",
      "Epoch 135 of 200 took 35.915s\n",
      "  training loss:\t\t37390.078711\n",
      "  validation loss:\t\t756.625220\n",
      "97433.4765625\n",
      "Epoch 136 of 200 took 37.408s\n",
      "  training loss:\t\t41133.715234\n",
      "  validation loss:\t\t1226.200540\n",
      "37770.25\n",
      "Epoch 137 of 200 took 33.716s\n",
      "  training loss:\t\t50590.207031\n",
      "  validation loss:\t\t883.124805\n",
      "16524.9003906\n",
      "Epoch 138 of 200 took 39.175s\n",
      "  training loss:\t\t29898.558008\n",
      "  validation loss:\t\t493.102356\n",
      "60970.8203125\n",
      "Epoch 139 of 200 took 39.936s\n",
      "  training loss:\t\t40085.039453\n",
      "  validation loss:\t\t854.268860\n",
      "31221.5371094\n",
      "Epoch 140 of 200 took 38.000s\n",
      "  training loss:\t\t39719.540234\n",
      "  validation loss:\t\t281.668924\n",
      "44666.4375\n",
      "Epoch 141 of 200 took 35.697s\n",
      "  training loss:\t\t36712.779687\n",
      "  validation loss:\t\t906.237714\n",
      "53899.453125\n",
      "Epoch 142 of 200 took 38.407s\n",
      "  training loss:\t\t39068.830078\n",
      "  validation loss:\t\t615.615912\n",
      "91561.8046875\n",
      "Epoch 143 of 200 took 39.556s\n",
      "  training loss:\t\t48129.712109\n",
      "  validation loss:\t\t1077.171124\n",
      "34558.2578125\n",
      "Epoch 144 of 200 took 40.798s\n",
      "  training loss:\t\t61936.821875\n",
      "  validation loss:\t\t1101.939771\n",
      "38778.2773438\n",
      "Epoch 145 of 200 took 34.817s\n",
      "  training loss:\t\t31475.112891\n",
      "  validation loss:\t\t753.687201\n",
      "28341.0839844\n",
      "Epoch 146 of 200 took 39.758s\n",
      "  training loss:\t\t57807.076953\n",
      "  validation loss:\t\t664.344095\n",
      "39493.1640625\n",
      "Epoch 147 of 200 took 38.720s\n",
      "  training loss:\t\t27541.170166\n",
      "  validation loss:\t\t718.010876\n",
      "19281.7421875\n",
      "Epoch 148 of 200 took 36.928s\n",
      "  training loss:\t\t38574.493359\n",
      "  validation loss:\t\t601.559790\n",
      "50103.390625\n",
      "Epoch 149 of 200 took 31.568s\n",
      "  training loss:\t\t26493.792578\n",
      "  validation loss:\t\t807.321936\n",
      "35470.3398438\n",
      "Epoch 150 of 200 took 34.039s\n",
      "  training loss:\t\t31648.264453\n",
      "  validation loss:\t\t699.843243\n",
      "75841.3359375\n",
      "Epoch 151 of 200 took 39.676s\n",
      "  training loss:\t\t45926.539453\n",
      "  validation loss:\t\t521.171890\n",
      "13079.7050781\n",
      "Epoch 152 of 200 took 32.429s\n",
      "  training loss:\t\t40516.362305\n",
      "  validation loss:\t\t690.997925\n",
      "46751.0898438\n",
      "Epoch 153 of 200 took 35.714s\n",
      "  training loss:\t\t31099.399609\n",
      "  validation loss:\t\t555.514587\n",
      "43504.5664062\n",
      "Epoch 154 of 200 took 32.981s\n",
      "  training loss:\t\t40795.796289\n",
      "  validation loss:\t\t551.781635\n",
      "41723.3046875\n",
      "Epoch 155 of 200 took 40.924s\n",
      "  training loss:\t\t33402.644824\n",
      "  validation loss:\t\t949.540363\n",
      "20308.671875\n",
      "Epoch 156 of 200 took 37.032s\n",
      "  training loss:\t\t38070.394922\n",
      "  validation loss:\t\t400.285541\n",
      "18650.2617188\n",
      "Epoch 157 of 200 took 40.767s\n",
      "  training loss:\t\t33202.975000\n",
      "  validation loss:\t\t591.120950\n",
      "37527.0390625\n",
      "Epoch 158 of 200 took 35.039s\n",
      "  training loss:\t\t24847.810547\n",
      "  validation loss:\t\t812.319513\n",
      "18710.0371094\n",
      "Epoch 159 of 200 took 42.540s\n",
      "  training loss:\t\t25661.944141\n",
      "  validation loss:\t\t551.116534\n",
      "18101.6015625\n",
      "Epoch 160 of 200 took 36.752s\n",
      "  training loss:\t\t23075.618945\n",
      "  validation loss:\t\t547.209499\n",
      "32820.984375\n",
      "Epoch 161 of 200 took 41.541s\n",
      "  training loss:\t\t36177.141992\n",
      "  validation loss:\t\t761.121045\n",
      "23871.5058594\n",
      "Epoch 162 of 200 took 44.558s\n",
      "  training loss:\t\t33156.602148\n",
      "  validation loss:\t\t675.191150\n",
      "42908.96875\n",
      "Epoch 163 of 200 took 42.737s\n",
      "  training loss:\t\t26518.966016\n",
      "  validation loss:\t\t523.067245\n",
      "13551.0117188\n",
      "Epoch 164 of 200 took 42.005s\n",
      "  training loss:\t\t19014.474414\n",
      "  validation loss:\t\t1033.394080\n",
      "10720.9677734\n",
      "Epoch 165 of 200 took 45.903s\n",
      "  training loss:\t\t19745.281836\n",
      "  validation loss:\t\t557.830951\n",
      "23478.3554688\n",
      "Epoch 166 of 200 took 40.792s\n",
      "  training loss:\t\t16326.137793\n",
      "  validation loss:\t\t686.724530\n",
      "13560.1113281\n",
      "Epoch 167 of 200 took 32.824s\n",
      "  training loss:\t\t22143.160938\n",
      "  validation loss:\t\t477.130933\n",
      "36178.1171875\n",
      "Epoch 168 of 200 took 38.916s\n",
      "  training loss:\t\t28457.061328\n",
      "  validation loss:\t\t912.707922\n",
      "24171.6113281\n",
      "Epoch 169 of 200 took 40.488s\n",
      "  training loss:\t\t39459.475781\n",
      "  validation loss:\t\t678.783624\n",
      "28439.9980469\n",
      "Epoch 170 of 200 took 39.860s\n",
      "  training loss:\t\t17992.308789\n",
      "  validation loss:\t\t552.607013\n",
      "18508.21875\n",
      "Epoch 171 of 200 took 39.393s\n",
      "  training loss:\t\t23990.716602\n",
      "  validation loss:\t\t618.661493\n",
      "63873.3320312\n",
      "Epoch 172 of 200 took 41.157s\n",
      "  training loss:\t\t42906.014062\n",
      "  validation loss:\t\t417.945230\n",
      "9597.39355469\n",
      "Epoch 173 of 200 took 31.770s\n",
      "  training loss:\t\t32067.131445\n",
      "  validation loss:\t\t391.842819\n",
      "38005.9570312\n",
      "Epoch 174 of 200 took 39.553s\n",
      "  training loss:\t\t39263.718359\n",
      "  validation loss:\t\t431.422937\n",
      "22775.5078125\n",
      "Epoch 175 of 200 took 43.460s\n",
      "  training loss:\t\t26562.438672\n",
      "  validation loss:\t\t546.512683\n",
      "31625.2363281\n",
      "Epoch 176 of 200 took 34.877s\n",
      "  training loss:\t\t25335.838086\n",
      "  validation loss:\t\t308.361247\n",
      "13996.2011719\n",
      "Epoch 177 of 200 took 33.634s\n",
      "  training loss:\t\t12817.468066\n",
      "  validation loss:\t\t628.579132\n",
      "8447.49316406\n",
      "Epoch 178 of 200 took 35.376s\n",
      "  training loss:\t\t12654.116992\n",
      "  validation loss:\t\t409.258951\n",
      "27453.6367188\n",
      "Epoch 179 of 200 took 39.158s\n",
      "  training loss:\t\t23948.464844\n",
      "  validation loss:\t\t249.834692\n",
      "18874.5097656\n",
      "Epoch 180 of 200 took 30.187s\n",
      "  training loss:\t\t21326.588281\n",
      "  validation loss:\t\t198.491841\n",
      "10280.0361328\n",
      "Epoch 181 of 200 took 37.724s\n",
      "  training loss:\t\t48904.630273\n",
      "  validation loss:\t\t407.562299\n",
      "32925.078125\n",
      "Epoch 182 of 200 took 30.867s\n",
      "  training loss:\t\t20763.688086\n",
      "  validation loss:\t\t606.825696\n",
      "25187.1015625\n",
      "Epoch 183 of 200 took 34.345s\n",
      "  training loss:\t\t29528.198047\n",
      "  validation loss:\t\t444.440227\n",
      "25628.1308594\n",
      "Epoch 184 of 200 took 28.623s\n",
      "  training loss:\t\t28563.799805\n",
      "  validation loss:\t\t248.159113\n",
      "49043.3554688\n",
      "Epoch 185 of 200 took 26.578s\n",
      "  training loss:\t\t27162.910938\n",
      "  validation loss:\t\t255.268906\n",
      "14694.7822266\n",
      "Epoch 186 of 200 took 27.341s\n",
      "  training loss:\t\t19415.512891\n",
      "  validation loss:\t\t378.220201\n",
      "2378.23242188\n",
      "Epoch 187 of 200 took 31.160s\n",
      "  training loss:\t\t19666.389062\n",
      "  validation loss:\t\t357.447684\n",
      "19761.2792969\n",
      "Epoch 188 of 200 took 32.412s\n",
      "  training loss:\t\t15264.740381\n",
      "  validation loss:\t\t313.146027\n",
      "4845.36132812\n",
      "Epoch 189 of 200 took 31.627s\n",
      "  training loss:\t\t14768.520117\n",
      "  validation loss:\t\t424.019803\n",
      "12654.2363281\n",
      "Epoch 190 of 200 took 39.414s\n",
      "  training loss:\t\t18550.764551\n",
      "  validation loss:\t\t271.057958\n",
      "12213.2070312\n",
      "Epoch 191 of 200 took 26.557s\n",
      "  training loss:\t\t18373.300781\n",
      "  validation loss:\t\t457.313704\n",
      "5818.21777344\n",
      "Epoch 192 of 200 took 31.100s\n",
      "  training loss:\t\t11663.653223\n",
      "  validation loss:\t\t261.867514\n",
      "21087.2890625\n",
      "Epoch 193 of 200 took 43.449s\n",
      "  training loss:\t\t21597.770508\n",
      "  validation loss:\t\t114.943671\n",
      "12127.0371094\n",
      "Epoch 194 of 200 took 34.087s\n",
      "  training loss:\t\t19634.663086\n",
      "  validation loss:\t\t601.218005\n",
      "9455.95019531\n",
      "Epoch 195 of 200 took 35.394s\n",
      "  training loss:\t\t18379.574219\n",
      "  validation loss:\t\t394.007803\n",
      "21000.5566406\n",
      "Epoch 196 of 200 took 27.276s\n",
      "  training loss:\t\t15439.185254\n",
      "  validation loss:\t\t299.131998\n",
      "11346.5068359\n",
      "Epoch 197 of 200 took 28.060s\n",
      "  training loss:\t\t12901.678223\n",
      "  validation loss:\t\t138.800697\n",
      "1265.65368652\n",
      "Epoch 198 of 200 took 30.076s\n",
      "  training loss:\t\t6986.154663\n",
      "  validation loss:\t\t490.076173\n",
      "7650.03222656\n",
      "Epoch 199 of 200 took 31.836s\n",
      "  training loss:\t\t11334.146680\n",
      "  validation loss:\t\t176.333736\n",
      "13685.3779297\n",
      "Epoch 200 of 200 took 27.501s\n",
      "  training loss:\t\t9635.563916\n",
      "  validation loss:\t\t211.342795\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(epoch, num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, batchs_per_epoch=batchs_per_epoch,\n",
    "                                     batchsize=batch_size, train=True, shuffle=True):\n",
    "        inputs_left, inputs_positive, inputs_negative = batch\n",
    "        err = train_fn(inputs_left, inputs_positive, inputs_negative, margin)\n",
    "        train_err += err\n",
    "        train_batches += 1\n",
    "    print(err)\n",
    "\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batchs_per_epoch=batchs_per_epoch,\n",
    "                                     batchsize=batch_size, train=False, shuffle=True):\n",
    "        inputs_left, inputs_positive, inputs_negative = batch\n",
    "        err = val_fn(inputs_left, inputs_positive, inputs_negative, margin)\n",
    "        val_err += err\n",
    "        val_batches += 1\n",
    "\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    train_errors.append(train_err / train_batches)\n",
    "    val_errors.append(val_err / val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_errors, 'r')\n",
    "plt.plot(val_errors, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import os\n",
    "\n",
    "import lasagne as nn\n",
    "\n",
    "def write_model_data(model, filename):\n",
    "    \"\"\"Pickels the parameters within a Lasagne model.\"\"\"\n",
    "    PARAM_EXTENSION = 'params'\n",
    "    data = nn.layers.get_all_param_values(model)\n",
    "    filename = os.path.join('./', filename)\n",
    "    filename = '%s.%s' % (filename, PARAM_EXTENSION)\n",
    "    with open(filename, 'w') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "write_model_data(nn_merge, 'model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "60px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
