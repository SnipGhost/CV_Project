{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем сиамскую сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"./../models/\"))\n",
    "from vgg import gen_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 1: GeForce GTX 1070 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(147)\n",
    "train_fn, val_fn, net = gen_net(False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = np.load('../data_set160_dim3.npz')\n",
    "X_train, y_train, X_val, y_val = files['X_train'], files['y_train'], files['X_test'], files['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# def transform(data, target):\n",
    "#     datagen = ImageDataGenerator(zca_whitening=True)\n",
    "#     datagen.fit(data)\n",
    "#     _data, _target = [], []\n",
    "#     for x, y in datagen.flow(data, target):\n",
    "#         _data.append(x.reshape(3, 160, 160))\n",
    "#         _target.append(y)\n",
    "#     return np.array(_data), np.array(_target)\n",
    "# X_train, y_train = transform(X_train, y_train)\n",
    "# X_test, y_test = transform(X_test, y_test)\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "datagen_train = ImageDataGenerator(zca_whitening=True)\n",
    "datagen_train.fit(X_train)\n",
    "datagen_test = ImageDataGenerator(zca_whitening=True)\n",
    "datagen_test.fit(X_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fictional_target = np.zeros(batchsize)\n",
    "\n",
    "def transform(data, target):\n",
    "    return np.array([x for x, _ in datagen.flow(data, target)])\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchs_per_epoch=100, batchsize=20, train=True, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "\n",
    "    left_indices = np.arange(len(inputs))\n",
    "    \n",
    "    if shuffle:\n",
    "        np.random.shuffle(left_indices)\n",
    "        \n",
    "    for _ in range(batchs_per_epoch):\n",
    "        full_lft_indxs = []\n",
    "        full_pos_indxs = []\n",
    "        full_neg_indxs = []\n",
    "        \n",
    "        for _ in range(batchsize):\n",
    "            start_idx = np.random.randint(low=0, high=len(left_indices))\n",
    "            full_lft_indxs.append(start_idx)\n",
    "            \n",
    "            pos_idxs = np.where(targets == targets[start_idx])[0]\n",
    "            b_idxs = np.random.randint(low=0, high=len(pos_idxs), size=1)\n",
    "            full_pos_indxs.append(pos_idxs[b_idxs[0]])\n",
    "            \n",
    "            neg_idxs = np.where(targets != targets[start_idx])[0]\n",
    "            b_idxs = np.random.randint(low=0, high=len(neg_idxs), size=1)\n",
    "            full_neg_indxs.append(neg_idxs[b_idxs[0]])\n",
    "\n",
    "        full_lft_indxs = np.array(full_lft_indxs)\n",
    "        full_pos_indxs = np.array(full_pos_indxs)\n",
    "        full_neg_indxs = np.array(full_neg_indxs)\n",
    "        \n",
    "        inputs_left = transform(inputs[full_lft_indxs], fictional_target)\n",
    "        inputs_positive = transform(inputs[full_pos_indxs], fictional_target)\n",
    "        inputs_negative = transform(inputs[full_neg_indxs], fictional_target)\n",
    "        \n",
    "        plt.imshow(input_left[0])\n",
    "#         yield inputs[full_lft_indxs], inputs[full_pos_indxs], inputs[full_neg_indxs]\n",
    "        yield inputs_left, inputs_positive, inputs_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "train_errors = []\n",
    "val_errors = []\n",
    "epoch = 0\n",
    "batch_size = 20\n",
    "batchs_per_epoch = 16\n",
    "\n",
    "margin = 1.242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(epoch, num_epochs):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, batchs_per_epoch=batchs_per_epoch,\n",
    "                                     batchsize=batch_size, train=True, shuffle=True):\n",
    "        inputs_left, inputs_positive, inputs_negative = batch\n",
    "        err = train_fn(inputs_left, inputs_positive, inputs_negative, margin)\n",
    "        train_err += err\n",
    "        train_batches += 1\n",
    "    print(err)\n",
    "\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batchs_per_epoch=batchs_per_epoch,\n",
    "                                     batchsize=batch_size, train=False, shuffle=True):\n",
    "        inputs_left, inputs_positive, inputs_negative = batch\n",
    "        err = val_fn(inputs_left, inputs_positive, inputs_negative, margin)\n",
    "        val_err += err\n",
    "        val_batches += 1\n",
    "\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    train_errors.append(train_err / train_batches)\n",
    "    val_errors.append(val_err / val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "import lasagne as nn\n",
    "\n",
    "def write_model_data(model, filename):\n",
    "    \"\"\"Pickels the parameters within a Lasagne model.\"\"\"\n",
    "    PARAM_EXTENSION = 'params'\n",
    "    data = nn.layers.get_all_param_values(model)\n",
    "    filename = os.path.join('./', filename)\n",
    "    filename = '%s.%s' % (filename, PARAM_EXTENSION)\n",
    "    with open(filename, 'w') as f:\n",
    "        pickle.dump(data, f)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_model_data(net, '../model_params/vgg-dim3-new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_errors, 'r')\n",
    "plt.plot(val_errors, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "60px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
